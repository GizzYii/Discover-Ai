# ğŸ¤– Yapay Zeka (YZ) Kara Kutu Problemi / AI Black Box Problem

---

## ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e

### ğŸ¬ Video Ã–zeti
Kara Kutu Problemi, bir yapay zeka algoritmasÄ±nÄ±n (Ã¶zellikle Derin Ã–ÄŸrenme modelleri) nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± tam olarak bilemememizi ifade eder. Model, karmaÅŸÄ±k girdiler alÄ±r ve bir Ã§Ä±ktÄ± Ã¼retir; ancak bu sÃ¼reÃ§ gizli kalÄ±r.  

**Video Ã–nerisi:** [Yapay Zekada Kara Kutu Problemi Videosu](#)

---

### ğŸ” Problemin TanÄ±mÄ± ve KÃ¶keni
- **Kara Kutu Problemi:** YZ algoritmalarÄ± girdileri alÄ±p Ã§Ä±ktÄ± Ã¼retir, fakat bu Ã§Ä±ktÄ±ya nasÄ±l ulaÅŸtÄ±ÄŸÄ± iÃ§eriden anlaÅŸÄ±lamaz.  
- **Derin Ã–ÄŸrenme:** YSAâ€™lar yÃ¼zlerce katman ve trilyonlarca aÄŸÄ±rlÄ±k ile Ã§alÄ±ÅŸÄ±r. Bu parametrelerin her biri karara katkÄ±da bulunur; ancak tÃ¼m etkileÅŸimi insan mantÄ±ÄŸÄ±yla takip etmek mÃ¼mkÃ¼n deÄŸildir.  
- **DoÄŸrusal Olmayan Ä°liÅŸkiler:** Model, veriler arasÄ±ndaki karmaÅŸÄ±k iliÅŸkileri Ã¶ÄŸrenir; basit â€œeÄŸer-o zamanâ€ kurallarÄ±yla aÃ§Ä±klanamaz.

---

### âš–ï¸ Etik ve Pratik Riskler
- **GÃ¼ven ve Sorumluluk:** HatalÄ± karar durumunda sistemin aÃ§Ä±klama yapamamasÄ±, gÃ¼ven ve hukuki sorumluluk sorunlarÄ± yaratÄ±r.  
- **Ã–nyargÄ± Tespiti:** Model eÄŸitim verilerindeki Ã¶nyargÄ±larÄ± yansÄ±tÄ±yorsa, bu ayrÄ±mcÄ± kararÄ±n nedenini tespit etmek zordur.  
- **Hata AyÄ±klama (Debugging):** KarmaÅŸÄ±k aÄŸ yapÄ±sÄ±, yanlÄ±ÅŸ Ã§Ä±ktÄ± durumunda sorunun kaynaÄŸÄ±nÄ± bulmayÄ± zorlaÅŸtÄ±rÄ±r.

---

### âœ… 2025 Durumu: Ã‡Ã¶zÃ¼m YollarÄ± (AÃ§Ä±klanabilir YZ - XAI)
Kara Kutu Problemi devam etse de, AÃ§Ä±klanabilir Yapay Zeka (eXplainable AI - XAI) ile kararlar daha anlaÅŸÄ±lÄ±r hale gelmektedir.  

| YÃ¶ntem | Ne Yapar? | Ã–rnek |
|--------|-----------|-------|
| **Ã–zellik Ã–nemi (SHAP/LIME)** | Modelin hangi girdi Ã¶zelliklerine aÄŸÄ±rlÄ±k verdiÄŸini gÃ¶sterir | Emlak YZâ€™si, fiyat tahmininde â€œokul puanÄ±â€ ve â€œmetrekareâ€ye %70 aÄŸÄ±rlÄ±k verir |
| **Dikkat HaritalarÄ± (Attention Maps)** | GÃ¶rsel/metinsel verilerde modelin hangi bÃ¶lÃ¼mlere odaklandÄ±ÄŸÄ±nÄ± gÃ¶sterir | YÃ¼z tanÄ±ma YZâ€™si, sadece â€œgÃ¶z Ã§evresiâ€ ve â€œburunâ€ kÄ±smÄ±na odaklanÄ±r |
| **Post-Hoc GerekÃ§elendirme** | Model karar verdikten sonra basit, anlaÅŸÄ±lÄ±r gerekÃ§e sunar | YZ, hastanÄ±n riskli olduÄŸunu bildirir ve gerekÃ§e olarak â€œdÃ¼ÅŸÃ¼k tansiyon ve yÃ¼ksek kolesterolâ€ sunar |

---

## ğŸ‡¬ğŸ‡§ English

### ğŸ¬ Video Summary
The Black Box Problem refers to the lack of transparency in AI algorithms (especially Deep Learning models). The model takes complex inputs and produces an output, but the process remains hidden.  

**Video Suggestion:** [AI Black Box Problem Video](#)

---

### ğŸ” Definition and Origin
- **Black Box Problem:** AI algorithms take inputs and produce outputs, but itâ€™s impossible to understand internally how they reach that output.  
- **Deep Learning:** Neural networks work with hundreds of layers and trillions of parameters, each contributing to the decision; tracking all interactions with human logic is impossible.  
- **Non-Linear Relationships:** Models learn complex relationships between data that cannot be expressed as simple â€œif-thenâ€ rules.

---

### âš–ï¸ Ethical and Practical Risks
- **Trust and Responsibility:** When a system makes a wrong decision, lack of explanation reduces trust and raises legal issues.  
- **Bias Detection:** If a model reflects biases in training data, it is difficult to detect and correct discriminatory decisions.  
- **Debugging:** Complex network structures make it almost impossible to trace the source of unexpected outputs.

---

### âœ… 2025 Status: Solutions (Explainable AI - XAI)
Although the Black Box Problem continues, Explainable AI (XAI) makes AI decisions more interpretable.  

| Method | What It Does | Example |
|--------|-------------|--------|
| **Feature Importance (SHAP/LIME)** | Shows which input features the model emphasizes | Real estate AI gives 70% weight to â€œschool ratingâ€ and â€œsquare metersâ€ |
| **Attention Maps** | Visualizes which parts of input the model focuses on | Facial recognition AI focuses only on the â€œeye areaâ€ and â€œnoseâ€ |
| **Post-Hoc Explanation** | Provides a human-understandable justification after the decision | AI flags a patient as high-risk and cites â€œlow blood pressure and high cholesterolâ€ |
